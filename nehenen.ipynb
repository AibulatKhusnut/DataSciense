{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8640d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,classification_report,precision_score,recall_score,f1_score\n",
    "from sklearn.utils import class_weight, compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15dd9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Администратор\\Downloads\\100_acc.csv\")\n",
    "y = df['label']\n",
    "df = df.drop('label', axis=1)\n",
    "x = df.drop('signal_id', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8581bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9083969465648855\n",
      "Accuracy1 clf: 0.916030534351145\n",
      "Accuracy2 mlp1: 0.8778625954198473\n",
      "Accuracy3logreg: 0.916030534351145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "gbt = GradientBoostingClassifier()\n",
    "gbt.fit(x_train, y_train)\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "mlp1 = MLPClassifier()\n",
    "mlp1.fit(x_train, y_train)\n",
    "    # Прогнозирование меток классов для тестового набора\n",
    "ypred0 = gbt.predict(x_test)\n",
    "ypred = clf.predict(x_test)\n",
    "ypred1 = mlp1.predict(x_test)\n",
    "ypred2 = logreg.predict(x_test)\n",
    "    # Вычисление метрик и сохранение их значений\n",
    "accuracy0 = accuracy_score(y_test, ypred0)\n",
    "accuracy1 = accuracy_score(y_test, ypred)\n",
    "accuracy2 = accuracy_score(y_test, ypred1)\n",
    "accuracy3 = accuracy_score(y_test, ypred2)\n",
    "    # Вывод метрик на каждой итерации\n",
    "print(f\"Accuracy0 gbt: {accuracy0}\")\n",
    "print(f\"Accuracy1 clf: {accuracy1}\")\n",
    "print(f\"Accuracy2 mlp1: {accuracy2}\")\n",
    "print(f\"Accuracy3logreg: {accuracy3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "211ecb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'C': 0.001, 'max_iter': 250, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 0.9235164835164836\n",
      "Accuracy: 0.916030534351145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression( class_weight='balanced')\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter' : [250, 300, 500, 600]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Наилучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cded07af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy logreg: 0.916030534351145\n"
     ]
    }
   ],
   "source": [
    "logreg1=LogisticRegression(C=0.001, max_iter= 250, penalty= 'l1', solver= 'liblinear',class_weight='balanced')\n",
    "logreg1.fit(x_train, y_train)\n",
    "ypred2 = logreg.predict(x_test)\n",
    "print(f\"Accuracy logreg: {accuracy3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9debe8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "1080 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"D:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648\n",
      " 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648 0.92351648]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.916030534351145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the grid of parameters to search\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Measure accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "951b2e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c5a9344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b4b3b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy1 clf: 0.916030534351145\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=42,bootstrap=True, max_depth=None, max_features='sqrt', min_samples_leaf= 1, min_samples_split= 2, n_estimators=200)\n",
    "clf.fit(x_train, y_train)\n",
    "ypred = clf.predict(x_test)\n",
    "accuracy1 = accuracy_score(y_test, ypred)\n",
    "print(f\"Accuracy1 clf: {accuracy1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae20002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "        'max_iter': [200, 500],\n",
    "    'learning_rate_init': [0.01, 0.001],\n",
    "    'batch_size': [32, 64]\n",
    "\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "clf = GridSearchCV(mlp, parameters, cv=3)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Лучшие параметры: \", clf.best_params_)\n",
    "print(\"Наилучший показатель: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2371325f",
   "metadata": {},
   "outputs": [],
   "source": [
    ",\n",
    "    'momentum': [0.9, 0.95],\n",
    "    'beta_1': [0.9, 0.95],\n",
    "    'beta_2': [0.999, 0.9],\n",
    "    'early_stopping': [True, False],\n",
    "    'validation_fraction': [0.1, 0.2],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'shuffle': [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffb5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(x)\n",
    "x_trains, x_tests, y_trains, y_tests = train_test_split(X_normalized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5879814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9083969465648855\n",
      "Accuracy1 clf: 0.916030534351145\n",
      "Accuracy2 mlp1: 0.9007633587786259\n",
      "Accuracy3logreg: 0.916030534351145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "gbt = GradientBoostingClassifier()\n",
    "gbt.fit(x_trains, y_trains)\n",
    "logreg=LogisticRegression(C=0.001, max_iter= 250, penalty= 'l1', solver= 'liblinear',class_weight={0: 0.1, 1: 0.9})\n",
    "logreg.fit(x_trains, y_trains)\n",
    "clf = RandomForestClassifier(bootstrap=True, max_depth=None, max_features= 'sqrt', min_samples_leaf= 1, min_samples_split= 2, n_estimators=100,class_weight={0: 0.1, 1: 0.9})\n",
    "clf.fit(x_trains, y_trains)\n",
    "mlp1 = MLPClassifier(max_iter=500)\n",
    "mlp1.fit(x_trains, y_trains)\n",
    "    # Прогнозирование меток классов для тестового набора\n",
    "ypred0 = gbt.predict(x_tests)\n",
    "ypred = clf.predict(x_tests)\n",
    "ypred1 = mlp1.predict(x_tests)\n",
    "ypred2 = logreg.predict(x_tests)\n",
    "    # Вычисление метрик и сохранение их значений\n",
    "accuracy0 = accuracy_score(y_tests, ypred0)\n",
    "accuracy1 = accuracy_score(y_tests, ypred)\n",
    "accuracy2 = accuracy_score(y_tests, ypred1)\n",
    "accuracy3 = accuracy_score(y_tests, ypred2)\n",
    "    # Вывод метрик на каждой итерации\n",
    "print(f\"Accuracy0 gbt: {accuracy0}\")\n",
    "print(f\"Accuracy1 clf: {accuracy1}\")\n",
    "print(f\"Accuracy2 mlp1: {accuracy2}\")\n",
    "print(f\"Accuracy3logreg: {accuracy3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607f8f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.66153495 0.65808725\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Администратор\\Downloads\\100_acc.csv\")\n",
    "y = df['label']\n",
    "x = df.drop('label', axis=1)\n",
    "q25 = np.percentile(x, 25)\n",
    "q75 = np.percentile(x, 75)\n",
    "iqr = q75 - q25\n",
    "min_value = q25 - 1.5 * iqr\n",
    "max_value = q75 + 1.5 * iqr\n",
    "print(min_value,max_value )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa16c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=x[(x >=-0.66153495) & (x<=0.65808725)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d32ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['signal_id'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb75aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    df,y\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd9341b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры:  {'learning_rate': 0.001, 'max_depth': 3, 'n_estimators': 100}\n",
      "Лучшая точность:  0.894201030927835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# Создание объекта модели Gradient Boosted Trees\n",
    "gbt = GradientBoostingClassifier()\n",
    "\n",
    "# Создание объекта GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gbt, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "\n",
    "# Поиск оптимальных параметров\n",
    "grid_search.fit(X_normalized, y)\n",
    "\n",
    "# Вывод оптимальных параметров и лучшего значения метрики\n",
    "print('Лучшие параметры: ', grid_search.best_params_)\n",
    "print('Лучшая точность: ', grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c382d2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>...</th>\n",
       "      <th>p120</th>\n",
       "      <th>p121</th>\n",
       "      <th>p122</th>\n",
       "      <th>p123</th>\n",
       "      <th>p124</th>\n",
       "      <th>p125</th>\n",
       "      <th>p126</th>\n",
       "      <th>p127</th>\n",
       "      <th>p128</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.177789</td>\n",
       "      <td>-0.081874</td>\n",
       "      <td>-0.096131</td>\n",
       "      <td>-0.099436</td>\n",
       "      <td>-0.098867</td>\n",
       "      <td>-0.105427</td>\n",
       "      <td>-0.083472</td>\n",
       "      <td>-0.074000</td>\n",
       "      <td>-0.065275</td>\n",
       "      <td>-0.061691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068265</td>\n",
       "      <td>-0.059327</td>\n",
       "      <td>-0.013739</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.009645</td>\n",
       "      <td>0.070163</td>\n",
       "      <td>0.108443</td>\n",
       "      <td>0.127638</td>\n",
       "      <td>0.099169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.010733</td>\n",
       "      <td>0.117607</td>\n",
       "      <td>0.259589</td>\n",
       "      <td>0.339589</td>\n",
       "      <td>0.329296</td>\n",
       "      <td>0.281260</td>\n",
       "      <td>0.115658</td>\n",
       "      <td>-0.172955</td>\n",
       "      <td>-0.247284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370135</td>\n",
       "      <td>0.344097</td>\n",
       "      <td>0.158927</td>\n",
       "      <td>-0.102145</td>\n",
       "      <td>-0.301141</td>\n",
       "      <td>-0.148649</td>\n",
       "      <td>0.263631</td>\n",
       "      <td>0.480440</td>\n",
       "      <td>0.420327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.221846</td>\n",
       "      <td>-0.247773</td>\n",
       "      <td>-0.187847</td>\n",
       "      <td>-0.181616</td>\n",
       "      <td>-0.108799</td>\n",
       "      <td>-0.099480</td>\n",
       "      <td>-0.083244</td>\n",
       "      <td>-0.054944</td>\n",
       "      <td>-0.100919</td>\n",
       "      <td>-0.067735</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086089</td>\n",
       "      <td>-0.080394</td>\n",
       "      <td>-0.089625</td>\n",
       "      <td>-0.122950</td>\n",
       "      <td>-0.074273</td>\n",
       "      <td>-0.018595</td>\n",
       "      <td>0.054752</td>\n",
       "      <td>0.097544</td>\n",
       "      <td>0.067837</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.411835</td>\n",
       "      <td>0.513823</td>\n",
       "      <td>0.558802</td>\n",
       "      <td>0.380244</td>\n",
       "      <td>0.210830</td>\n",
       "      <td>0.174093</td>\n",
       "      <td>0.102772</td>\n",
       "      <td>-0.051933</td>\n",
       "      <td>-0.237179</td>\n",
       "      <td>-0.245491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113856</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>-0.112094</td>\n",
       "      <td>-0.133700</td>\n",
       "      <td>-0.024104</td>\n",
       "      <td>-0.042590</td>\n",
       "      <td>-0.062838</td>\n",
       "      <td>-0.078137</td>\n",
       "      <td>-0.194478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.221770</td>\n",
       "      <td>-0.026863</td>\n",
       "      <td>-0.249447</td>\n",
       "      <td>-0.340728</td>\n",
       "      <td>-0.288676</td>\n",
       "      <td>-0.207364</td>\n",
       "      <td>-0.155768</td>\n",
       "      <td>-0.091768</td>\n",
       "      <td>-0.119012</td>\n",
       "      <td>-0.149473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216549</td>\n",
       "      <td>-0.167078</td>\n",
       "      <td>-0.077491</td>\n",
       "      <td>-0.115439</td>\n",
       "      <td>-0.126838</td>\n",
       "      <td>-0.087323</td>\n",
       "      <td>-0.115734</td>\n",
       "      <td>-0.102995</td>\n",
       "      <td>-0.098657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0.056921</td>\n",
       "      <td>0.091304</td>\n",
       "      <td>0.054220</td>\n",
       "      <td>-0.056340</td>\n",
       "      <td>-0.200133</td>\n",
       "      <td>-0.296154</td>\n",
       "      <td>-0.317342</td>\n",
       "      <td>-0.262904</td>\n",
       "      <td>-0.205185</td>\n",
       "      <td>-0.183314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207767</td>\n",
       "      <td>-0.190373</td>\n",
       "      <td>-0.200115</td>\n",
       "      <td>-0.189764</td>\n",
       "      <td>-0.186473</td>\n",
       "      <td>-0.148881</td>\n",
       "      <td>-0.042340</td>\n",
       "      <td>0.131701</td>\n",
       "      <td>0.275289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>-0.384823</td>\n",
       "      <td>-0.271724</td>\n",
       "      <td>-0.214179</td>\n",
       "      <td>-0.200048</td>\n",
       "      <td>-0.161976</td>\n",
       "      <td>-0.206387</td>\n",
       "      <td>-0.091266</td>\n",
       "      <td>0.021260</td>\n",
       "      <td>0.066322</td>\n",
       "      <td>0.150286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045515</td>\n",
       "      <td>0.290182</td>\n",
       "      <td>0.513904</td>\n",
       "      <td>0.396371</td>\n",
       "      <td>0.063130</td>\n",
       "      <td>-0.264255</td>\n",
       "      <td>-0.466529</td>\n",
       "      <td>-0.474740</td>\n",
       "      <td>-0.495064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>-0.154442</td>\n",
       "      <td>-0.220017</td>\n",
       "      <td>-0.188431</td>\n",
       "      <td>-0.076496</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>0.301737</td>\n",
       "      <td>0.257763</td>\n",
       "      <td>0.151815</td>\n",
       "      <td>0.025748</td>\n",
       "      <td>-0.098116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046153</td>\n",
       "      <td>-0.055986</td>\n",
       "      <td>-0.074588</td>\n",
       "      <td>-0.156756</td>\n",
       "      <td>-0.257193</td>\n",
       "      <td>-0.237640</td>\n",
       "      <td>-0.179205</td>\n",
       "      <td>-0.079585</td>\n",
       "      <td>-0.025869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.104295</td>\n",
       "      <td>0.109067</td>\n",
       "      <td>0.045116</td>\n",
       "      <td>-0.033823</td>\n",
       "      <td>-0.072836</td>\n",
       "      <td>-0.054253</td>\n",
       "      <td>-0.014003</td>\n",
       "      <td>0.027218</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016502</td>\n",
       "      <td>-0.022746</td>\n",
       "      <td>-0.041478</td>\n",
       "      <td>-0.011162</td>\n",
       "      <td>-0.018928</td>\n",
       "      <td>-0.004817</td>\n",
       "      <td>0.032872</td>\n",
       "      <td>0.027806</td>\n",
       "      <td>0.033331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>-0.104234</td>\n",
       "      <td>-0.085259</td>\n",
       "      <td>-0.043942</td>\n",
       "      <td>-0.030790</td>\n",
       "      <td>0.026148</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.058006</td>\n",
       "      <td>0.125277</td>\n",
       "      <td>0.238481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159490</td>\n",
       "      <td>-0.126357</td>\n",
       "      <td>-0.094226</td>\n",
       "      <td>-0.072689</td>\n",
       "      <td>-0.132456</td>\n",
       "      <td>-0.135855</td>\n",
       "      <td>-0.079241</td>\n",
       "      <td>-0.015215</td>\n",
       "      <td>0.021913</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           p1        p2        p3        p4        p5        p6        p7  \\\n",
       "0   -0.177789 -0.081874 -0.096131 -0.099436 -0.098867 -0.105427 -0.083472   \n",
       "1    0.010337  0.010733  0.117607  0.259589  0.339589  0.329296  0.281260   \n",
       "2   -0.221846 -0.247773 -0.187847 -0.181616 -0.108799 -0.099480 -0.083244   \n",
       "3    0.411835  0.513823  0.558802  0.380244  0.210830  0.174093  0.102772   \n",
       "4    0.221770 -0.026863 -0.249447 -0.340728 -0.288676 -0.207364 -0.155768   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "646  0.056921  0.091304  0.054220 -0.056340 -0.200133 -0.296154 -0.317342   \n",
       "647 -0.384823 -0.271724 -0.214179 -0.200048 -0.161976 -0.206387 -0.091266   \n",
       "648 -0.154442 -0.220017 -0.188431 -0.076496  0.132110  0.301737  0.257763   \n",
       "650  0.104295  0.109067  0.045116 -0.033823 -0.072836 -0.054253 -0.014003   \n",
       "651 -0.104234 -0.085259 -0.043942 -0.030790  0.026148  0.028789  0.004455   \n",
       "\n",
       "           p8        p9       p10  ...      p120      p121      p122  \\\n",
       "0   -0.074000 -0.065275 -0.061691  ... -0.068265 -0.059327 -0.013739   \n",
       "1    0.115658 -0.172955 -0.247284  ...  0.370135  0.344097  0.158927   \n",
       "2   -0.054944 -0.100919 -0.067735  ... -0.086089 -0.080394 -0.089625   \n",
       "3   -0.051933 -0.237179 -0.245491  ...  0.113856  0.014483 -0.112094   \n",
       "4   -0.091768 -0.119012 -0.149473  ... -0.216549 -0.167078 -0.077491   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "646 -0.262904 -0.205185 -0.183314  ... -0.207767 -0.190373 -0.200115   \n",
       "647  0.021260  0.066322  0.150286  ...  0.045515  0.290182  0.513904   \n",
       "648  0.151815  0.025748 -0.098116  ... -0.046153 -0.055986 -0.074588   \n",
       "650  0.027218  0.054011  0.020000  ... -0.016502 -0.022746 -0.041478   \n",
       "651  0.058006  0.125277  0.238481  ... -0.159490 -0.126357 -0.094226   \n",
       "\n",
       "         p123      p124      p125      p126      p127      p128  label  \n",
       "0    0.009359  0.009645  0.070163  0.108443  0.127638  0.099169      0  \n",
       "1   -0.102145 -0.301141 -0.148649  0.263631  0.480440  0.420327      0  \n",
       "2   -0.122950 -0.074273 -0.018595  0.054752  0.097544  0.067837      0  \n",
       "3   -0.133700 -0.024104 -0.042590 -0.062838 -0.078137 -0.194478      0  \n",
       "4   -0.115439 -0.126838 -0.087323 -0.115734 -0.102995 -0.098657      0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "646 -0.189764 -0.186473 -0.148881 -0.042340  0.131701  0.275289      0  \n",
       "647  0.396371  0.063130 -0.264255 -0.466529 -0.474740 -0.495064      0  \n",
       "648 -0.156756 -0.257193 -0.237640 -0.179205 -0.079585 -0.025869      1  \n",
       "650 -0.011162 -0.018928 -0.004817  0.032872  0.027806  0.033331      0  \n",
       "651 -0.072689 -0.132456 -0.135855 -0.079241 -0.015215  0.021913      0  \n",
       "\n",
       "[482 rows x 129 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c938ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9381443298969072\n",
      "Accuracy1 clf: 0.9381443298969072\n",
      "Accuracy2 mlp1: 0.8556701030927835\n",
      "Accuracy3 logreg: 0.9381443298969072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = df['label']\n",
    "x = df.drop('label', axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(x)\n",
    "x_trains, x_tests, y_trains, y_tests = train_test_split(X_normalized, y, test_size=0.2, random_state=25)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "gbt = GradientBoostingClassifier(learning_rate= 0.001, max_depth= 3, n_estimators= 100)\n",
    "gbt.fit(x_trains, y_trains)\n",
    "logreg=LogisticRegression(C=0.001, max_iter= 250, penalty= 'l1', solver= 'liblinear',class_weight='balanced')\n",
    "logreg.fit(x_trains, y_trains)\n",
    "clf = RandomForestClassifier(bootstrap=True, max_depth=None, max_features= 'sqrt', min_samples_leaf= 1, min_samples_split= 2, n_estimators=100,class_weight='balanced')\n",
    "clf.fit(x_trains, y_trains)\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "mlp1.fit(x_trains, y_trains)\n",
    "    # Прогнозирование меток классов для тестового набора\n",
    "ypred0 = gbt.predict(x_tests)\n",
    "ypred = clf.predict(x_tests)\n",
    "ypred1 = mlp1.predict(x_tests)\n",
    "ypred2 = logreg.predict(x_tests)\n",
    "    # Вычисление метрик и сохранение их значений\n",
    "accuracy0 = accuracy_score(y_tests, ypred0)\n",
    "accuracy1 = accuracy_score(y_tests, ypred)\n",
    "accuracy2 = accuracy_score(y_tests, ypred1)\n",
    "accuracy3 = accuracy_score(y_tests, ypred2)\n",
    "    # Вывод метрик на каждой итерации\n",
    "print(f\"Accuracy0 gbt: {accuracy0}\")\n",
    "print(f\"Accuracy1 clf: {accuracy1}\")\n",
    "print(f\"Accuracy2 mlp1: {accuracy2}\")\n",
    "print(f\"Accuracy3 logreg: {accuracy3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8018740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8865979381443299\n",
      "Accuracy1 clf: 0.8865979381443299\n",
      "Accuracy2 mlp1: 0.8762886597938144\n",
      "Accuracy3 logreg: 0.8865979381443299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9072164948453608\n",
      "Accuracy1 clf: 0.9072164948453608\n",
      "Accuracy2 mlp1: 0.9072164948453608\n",
      "Accuracy3 logreg: 0.9072164948453608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9175257731958762\n",
      "Accuracy1 clf: 0.9175257731958762\n",
      "Accuracy2 mlp1: 0.9072164948453608\n",
      "Accuracy3 logreg: 0.9175257731958762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9072164948453608\n",
      "Accuracy1 clf: 0.9072164948453608\n",
      "Accuracy2 mlp1: 0.8865979381443299\n",
      "Accuracy3 logreg: 0.9072164948453608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8556701030927835\n",
      "Accuracy1 clf: 0.8556701030927835\n",
      "Accuracy2 mlp1: 0.845360824742268\n",
      "Accuracy3 logreg: 0.8556701030927835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8865979381443299\n",
      "Accuracy1 clf: 0.8865979381443299\n",
      "Accuracy2 mlp1: 0.8762886597938144\n",
      "Accuracy3 logreg: 0.8865979381443299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8762886597938144\n",
      "Accuracy1 clf: 0.8762886597938144\n",
      "Accuracy2 mlp1: 0.845360824742268\n",
      "Accuracy3 logreg: 0.8762886597938144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9072164948453608\n",
      "Accuracy1 clf: 0.9072164948453608\n",
      "Accuracy2 mlp1: 0.8556701030927835\n",
      "Accuracy3 logreg: 0.9072164948453608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8969072164948454\n",
      "Accuracy1 clf: 0.8969072164948454\n",
      "Accuracy2 mlp1: 0.865979381443299\n",
      "Accuracy3 logreg: 0.8969072164948454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.845360824742268\n",
      "Accuracy1 clf: 0.845360824742268\n",
      "Accuracy2 mlp1: 0.8247422680412371\n",
      "Accuracy3 logreg: 0.845360824742268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9278350515463918\n",
      "Accuracy1 clf: 0.9278350515463918\n",
      "Accuracy2 mlp1: 0.8969072164948454\n",
      "Accuracy3 logreg: 0.9278350515463918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9175257731958762\n",
      "Accuracy1 clf: 0.9175257731958762\n",
      "Accuracy2 mlp1: 0.8762886597938144\n",
      "Accuracy3 logreg: 0.9175257731958762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.865979381443299\n",
      "Accuracy1 clf: 0.865979381443299\n",
      "Accuracy2 mlp1: 0.8144329896907216\n",
      "Accuracy3 logreg: 0.865979381443299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8969072164948454\n",
      "Accuracy1 clf: 0.8969072164948454\n",
      "Accuracy2 mlp1: 0.845360824742268\n",
      "Accuracy3 logreg: 0.8969072164948454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8762886597938144\n",
      "Accuracy1 clf: 0.8762886597938144\n",
      "Accuracy2 mlp1: 0.8350515463917526\n",
      "Accuracy3 logreg: 0.8762886597938144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.865979381443299\n",
      "Accuracy1 clf: 0.865979381443299\n",
      "Accuracy2 mlp1: 0.8144329896907216\n",
      "Accuracy3 logreg: 0.865979381443299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9278350515463918\n",
      "Accuracy1 clf: 0.9278350515463918\n",
      "Accuracy2 mlp1: 0.8762886597938144\n",
      "Accuracy3 logreg: 0.9278350515463918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8865979381443299\n",
      "Accuracy1 clf: 0.8865979381443299\n",
      "Accuracy2 mlp1: 0.845360824742268\n",
      "Accuracy3 logreg: 0.8865979381443299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.8969072164948454\n",
      "Accuracy1 clf: 0.8969072164948454\n",
      "Accuracy2 mlp1: 0.8969072164948454\n",
      "Accuracy3 logreg: 0.8969072164948454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9278350515463918\n",
      "Accuracy1 clf: 0.9278350515463918\n",
      "Accuracy2 mlp1: 0.9175257731958762\n",
      "Accuracy3 logreg: 0.9278350515463918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9072164948453608\n",
      "Accuracy1 clf: 0.9072164948453608\n",
      "Accuracy2 mlp1: 0.8556701030927835\n",
      "Accuracy3 logreg: 0.9072164948453608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy0 gbt: 0.9278350515463918\n",
      "Accuracy1 clf: 0.9278350515463918\n",
      "Accuracy2 mlp1: 0.8969072164948454\n",
      "Accuracy3 logreg: 0.9278350515463918\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(25):    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_normalized = scaler.fit_transform(x)\n",
    "    x_trains, x_tests, y_trains, y_tests = train_test_split(X_normalized, y, test_size=0.2, shuffle=True)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    gbt = GradientBoostingClassifier(learning_rate= 0.001, max_depth= 3, n_estimators= 100)\n",
    "    gbt.fit(x_trains, y_trains)\n",
    "    logreg=LogisticRegression(C=0.001, max_iter= 250, penalty= 'l1', solver= 'liblinear',class_weight='balanced')\n",
    "    logreg.fit(x_trains, y_trains)\n",
    "    clf = RandomForestClassifier(bootstrap=True, max_depth=None, max_features= 'sqrt', min_samples_leaf= 1, min_samples_split= 2, n_estimators=100,class_weight='balanced')\n",
    "    clf.fit(x_trains, y_trains)\n",
    "    mlp1 = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "    mlp1.fit(x_trains, y_trains)\n",
    "        # Прогнозирование меток классов для тестового набора\n",
    "    ypred0 = gbt.predict(x_tests)\n",
    "    ypred = clf.predict(x_tests)\n",
    "    ypred1 = mlp1.predict(x_tests)\n",
    "    ypred2 = logreg.predict(x_tests)\n",
    "        # Вычисление метрик и сохранение их значений\n",
    "    accuracy0 = accuracy_score(y_tests, ypred0)\n",
    "    accuracy1 = accuracy_score(y_tests, ypred)\n",
    "    accuracy2 = accuracy_score(y_tests, ypred1)\n",
    "    accuracy3 = accuracy_score(y_tests, ypred2)\n",
    "        # Вывод метрик на каждой итерации\n",
    "    print(f\"Accuracy0 gbt: {accuracy0}\")\n",
    "    print(f\"Accuracy1 clf: {accuracy1}\")\n",
    "    print(f\"Accuracy2 mlp1: {accuracy2}\")\n",
    "    print(f\"Accuracy3 logreg: {accuracy3}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8350b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
